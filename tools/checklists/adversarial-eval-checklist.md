---
title: Adversarial Evaluation Checklist
version: 1.0
last_updated: 2025-08-21
tags: [Adversarial Testing, AI Security, Checklist]
---

# Adversarial Evaluation Checklist

## Ziel
Robustheit von KI-Modellen gegen adversarial Manipulationen sicherstellen.

## Checkpunkte
- [ ] Evasion Attacks: Adversarial Examples generiert und getestet  
- [ ] Data Poisoning: Training mit manipulierten Daten simuliert  
- [ ] Model Inversion: Pr√ºfung auf Rekonstruktion von Trainingsdaten  
- [ ] Model Extraction: Schutz vor API-Abfragen (Rate Limiting, Throttling)  
- [ ] Bias Testing: Tests auf diskriminierende Outputs  
- [ ] Logging der Ergebnisse & Abweichungen  
- [ ] Red Team Reports vorhanden und versioniert  
